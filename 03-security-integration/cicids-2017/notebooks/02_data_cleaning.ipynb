{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49d4f84e",
   "metadata": {},
   "source": [
    "# CICIDS 2017 â€“ Data Cleaning\n",
    "\n",
    "This notebook focuses on improving data quality while preserving\n",
    "rare but meaningful security events.\n",
    "\n",
    "Cleaning decisions are conservative and explicitly justified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37c3f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e662de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(r\"D:\\MachineLearningCVE\\Monday-WorkingHours.pcap_ISCX.csv\")\n",
    "data2 = pd.read_csv(r\"D:\\MachineLearningCVE\\Tuesday-WorkingHours.pcap_ISCX.csv\")\n",
    "data3 = pd.read_csv(r\"D:\\MachineLearningCVE\\Wednesday-workingHours.pcap_ISCX.csv\")\n",
    "data4 = pd.read_csv(r\"D:\\MachineLearningCVE\\Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\")\n",
    "data5 = pd.read_csv(r\"D:\\MachineLearningCVE\\Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\")\n",
    "data6 = pd.read_csv(r\"D:\\MachineLearningCVE\\Friday-WorkingHours-Morning.pcap_ISCX.csv\")\n",
    "data7 = pd.read_csv(r\"D:\\MachineLearningCVE\\Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\")\n",
    "data8 = pd.read_csv(r\"D:\\MachineLearningCVE\\Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")\n",
    "\n",
    "data = pd.concat(\n",
    "    [data1, data2, data3, data4, data5, data6, data7, data8],\n",
    "    ignore_index=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd21dcc",
   "metadata": {},
   "source": [
    "## Cleaning Philosophy\n",
    "\n",
    "Security datasets often contain rare, extreme, or noisy values that\n",
    "may represent attacks rather than errors.\n",
    "\n",
    "Therefore:\n",
    "- Only clearly invalid values are corrected\n",
    "- Rare events are preserved\n",
    "- Every modification is explicitly justified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d44481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading/trailing whitespace from column names\n",
    "data.columns = data.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4116db98",
   "metadata": {},
   "source": [
    "## Column Name Normalization\n",
    "\n",
    "Some CICIDS 2017 columns contain leading or trailing whitespace.\n",
    "This step improves reliability and prevents accidental KeyErrors\n",
    "without altering the underlying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b259530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace infinite values with NaN\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc6b044",
   "metadata": {},
   "source": [
    "## Infinite Values Handling\n",
    "\n",
    "Infinite values cannot be processed reliably by analytical tools.\n",
    "They are treated as missing values and handled conservatively\n",
    "in the next step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eae1375c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flow Bytes/s      2867\n",
       "Flow Packets/s    2867\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_counts = data.isna().sum()\n",
    "missing_counts[missing_counts > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531d3483",
   "metadata": {},
   "source": [
    "## Missing Value Strategy\n",
    "\n",
    "Missing values are handled cautiously.\n",
    "\n",
    "Rows with missing values in critical numeric features are removed,\n",
    "as imputation could introduce artificial patterns in security data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0c913de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before: 2830743\n",
      "Rows after: 2827876\n"
     ]
    }
   ],
   "source": [
    "data_before = data.shape[0]\n",
    "data.dropna(inplace=True)\n",
    "data_after = data.shape[0]\n",
    "\n",
    "print(f\"Rows before: {data_before}\")\n",
    "print(f\"Rows after: {data_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74bade3",
   "metadata": {},
   "source": [
    "> Note: Row removal due to missing values affects a small fraction of the dataset\n",
    "and was chosen over imputation to avoid introducing artificial patterns\n",
    "in security-sensitive features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae449a03",
   "metadata": {},
   "source": [
    "## Duplicate Records\n",
    "\n",
    "Exact duplicate rows do not add analytical value and may bias\n",
    "distribution-based analysis.\n",
    "\n",
    "Only exact duplicates are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00530dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before duplicate removal: 2827876\n",
      "Rows after duplicate removal: 2520798\n"
     ]
    }
   ],
   "source": [
    "dup_before = data.shape[0]\n",
    "data.drop_duplicates(inplace=True)\n",
    "dup_after = data.shape[0]\n",
    "\n",
    "print(f\"Rows before duplicate removal: {dup_before}\")\n",
    "print(f\"Rows after duplicate removal: {dup_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ea035eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final cleaned dataset shape: (2520798, 79)\n"
     ]
    }
   ],
   "source": [
    "print(\"Final cleaned dataset shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e24a61",
   "metadata": {},
   "source": [
    "## Cleaning Summary\n",
    "\n",
    "The following steps were applied:\n",
    "- Normalized column names\n",
    "- Replaced infinite values with NaN\n",
    "- Removed rows with missing values\n",
    "- Removed exact duplicate records\n",
    "\n",
    "No feature engineering or scaling was performed.\n",
    "Rare events were preserved wherever possible.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cicids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
